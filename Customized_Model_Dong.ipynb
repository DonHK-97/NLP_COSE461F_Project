{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Customized_Model_Dong.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMoVg89nzOUfBro/oTGxfNP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"U8cz9t0xLwaK"},"source":["import torch\n","import torch.nn as nn\n","import fastai.layers as L\n","import torch.nn.functional as F\n","from collections import OrderedDict\n","\n","torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"usNNor0LM0Hx"},"source":["def Embedding(weight_matrix):\n","\n","  num_embeddings, dim_embeddings = weight_matrix.shape\n","  weights_matrix = torch.from_numpy(weights_matrix)\n","\n","  Emb_layer = nn.Embedding(num_embeddings, dim_embeddings, padding_idx=1).to('cuda')\n","  Emb_layer.load_state_dict({'Weight' : weight_matrix})\n","  Emb_layer.weight.requires_grad = False\n","\n","  return Emb_layer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pojPmvFnN4dD"},"source":["class downsample_merger(nn.Module):\n","  def __init__(self, input_channel, dense = True):\n","    super().__init()\n","    self.downsample = L.conv1d(input_channel, input_channel * 2, stride = 2)\n","\n","  def forward(self, x): return x + self.downsample(x.orig)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7JdIePMJPtXN"},"source":["def transition(input_channel):\n","  trans_layer = L.SequentialEX(\n","      L.conv1d(input_channel, input_channel * 2, ks = 3, stride = 2, padding = 1),\n","      downsample_merger(input_channel)\n","  )\n","  return trans_layer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_GK5HNPSdDj"},"source":["def residual(input_channel, leaky):\n","  kwargs = {'is_1d' : True, 'self_attention' : True, 'leaky' : leaky}\n","  return L.res_block(input_channel, bottle = True, **kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_qrtpFxSVChE"},"source":["class DeepResNet(nn.Module):\n","  def __init__(self, weights_matrix, layers = (4, 4, 7, 7),\n","               input_channel = 16, dim_embed = 50, leaky = 0.02, dropout = 0.25):\n","    super(DeepResNet, self).__init__()\n","\n","    self.embedding = Embedding(weight_matrix)\n","    self.init_conv = L.conv1d(1, input_channel, ks = (3, dim_embed),\n","                              stride = 1, padding = (1, 0), bias = False)\n","    self.dropout = dropout\n","    \n","    self.features = nn.Sequential(OrderedDict([\n","                                                ('initial_conv', self.init_conv),\n","                                                ('init_norm', nn.BatchNorm1d(input_channel)),\n","                                                ('init_LeakyReLU', nn.LeakyReLU(inplace = True))\n","    ]))\n","\n","    num_features = inplanes\n","\n","    for count, layer in enmerate(layers):\n","      self.features.add_module('residual #', count + 1, self.initial_block(num_features, layer))\n","\n","      if count < len(layers):\n","        self.features.add_module('transition #', count + 1, transition(num_features))\n","        num_features = num_features * 2\n","\n","    self.leakyrelu = L.relu(inplace = True, leaky = leaky)\n","    self.maxpool = nn.AdaptiveMaxPool1d(1)\n","    self.FC1 = nn.Linear(num_features, num_features * 2)\n","    self.classifier = nn.Linear(num_features * 2, 2)\n","\n","    for module in self.modules():\n","      if isinstance(module, nn.BatchNorm1d):\n","        nn.init.xavier_uniform_(module.weight, 1)\n","        nn.init.xavier_uniform_(module.bias, 0)\n","      elif isinstance(module, nn.Linear):\n","        nn.init.xavier_uniform_(module.bias, 0)\n","  \n","  def initial_block(self, output_channel, layer_counts, leaky):\n","    layers = []\n","\n","    for counts in range(0, layer_counts):\n","      \n","      layers.append(residual(output_channel, leaky))\n","      if counts < layer_count: layers.appned(nn.Dropout(p = self.dropout, inplace = True))\n","\n","    return nn.Sequential(*layers)\n","\n","  def forward(self, x):\n","\n","    x = self.embedding(x).unsqueeze(1)\n","\n","    for count, layers in enumarate(self.features):\n","      if count is 1: x = x.squeeze(3)\n","      x = layer(x)\n","\n","    x = self.maxpool(x).view(x.size(0), -1)\n","    x = self.FC1(x)\n","    x = self.leakyrelu(x)\n","    x = self.classifier(x)\n","\n","    return x"],"execution_count":null,"outputs":[]}]}